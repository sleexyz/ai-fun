{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 2 # batch, time, channels\n",
    "x = torch.randn(B, T, C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x bag of words\n",
    "xbow = torch.zeros((B, T, C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t + 1] # (t, C)\n",
    "        xbow[b, t] = torch.mean(xprev, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.3596, -0.9152],\n",
       "        [ 0.6258,  0.0255],\n",
       "        [ 0.9545,  0.0643],\n",
       "        [ 0.3612,  1.1679],\n",
       "        [-1.3499, -0.5102],\n",
       "        [ 0.2360, -0.2398],\n",
       "        [-0.9211,  1.5433]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.0894, -0.4926],\n",
       "        [ 0.1490, -0.3199],\n",
       "        [ 0.3504, -0.2238],\n",
       "        [ 0.3525,  0.0545],\n",
       "        [ 0.0688, -0.0396],\n",
       "        [ 0.0927, -0.0682],\n",
       "        [-0.0341,  0.1332]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 32])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "print(tril)\n",
    "attn = torch.zeros((T, T))\n",
    "attn = attn.masked_fill(tril == 0, float('-inf'))\n",
    "print(attn)\n",
    "attn = F.softmax(attn, dim=1)\n",
    "print(attn)\n",
    "xbow3 = attn @ x\n",
    "\n",
    "\n",
    "\n",
    "xbow3.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "# data dependent context\n",
    "# query and key vector\n",
    "# query: \"what am i looking for\"?\n",
    "# key: \"what do I contain\"\n",
    "# dot product between key and query\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 32 # batch, time, channels\n",
    "\n",
    "# in channel-space\n",
    "x = torch.randn(B, T, C) # (B, T, C)\n",
    "\n",
    "head_size = 16\n",
    "\n",
    "key = nn.Linear(C, head_size, bias=False)   # (C, 16)\n",
    "query = nn.Linear(C, head_size, bias=False) # (C, 16)\n",
    "value = nn.Linear(C, head_size, bias=False) # (C, 16)\n",
    "\n",
    "# we shrink to key space (features weighting importance in)\n",
    "# question: for transformers, why is one key and one query? Isn't it basically symmetric?\n",
    "k = key(x)   # (B, T, C) @ (C, 16) = (B, T, 16)\n",
    "q = query(x) # (B, T, C) @ (C, 16) = (B, T, 16)\n",
    "\n",
    "# Attention matrix\n",
    "# TxT\n",
    "attn = q @ k.transpose(-2, -1) * C**-0.5 # (B, T, 16) @ (B, 16, T)  =  (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "# wei = torch.zeros((T, T))\n",
    "\n",
    "# remove this block to make it a \"encoder block\"\n",
    "# right now it's a decoder block\n",
    "attn = attn.masked_fill(tril == 0, float('-inf'))\n",
    "\n",
    "# Softmax attention weights\n",
    "attn = F.softmax(attn, dim=-1) \n",
    "\n",
    "v = value(x)\n",
    "\n",
    "out = attn @ v # (B, T, T) @ (B, T, 16) = (B, T, 16)\n",
    "\n",
    "out.shape\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets try with einsum\n",
    "B, T, C = 4, 8, 32 # batch, time, channels\n",
    "\n",
    "x = torch.randn(B, T, C) # (B, T, C)\n",
    "head_size = 16\n",
    "\n",
    "key = nn.Linear(C, head_size, bias=False)   # (C, 16)\n",
    "query = nn.Linear(C, head_size, bias=False) # (C, 16)\n",
    "value = nn.Linear(C, head_size, bias=False) # (C, 16)\n",
    "\n",
    "k = key(x)   # (B, T, C) @ (C, 16) = (B, T, 16)\n",
    "q = query(x) # (B, T, C) @ (C, 16) = (B, T, 16)\n",
    "attn = torch.einsum(\"b i h , b j h -> b i j\", q, k) * C ** -0.5\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "attn = attn.masked_fill(tril == 0, float('-inf'))\n",
    "\n",
    "attn = F.softmax(attn, dim=-1) \n",
    "\n",
    "v = value(x)\n",
    "out = torch.einsum(\"b t t, b t h -> b t h\", attn, v)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 32])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ok multi-head attention\n",
    "B, T, C, nH = 4, 8, 32, 2 # batch, time, channels, num_heads\n",
    "\n",
    "x = torch.randn(B, T, C) # (B, T, C)\n",
    "\n",
    "head_size = 16\n",
    "\n",
    "\n",
    "# okay that's annoying. head_size * num_heads = C\n",
    "\n",
    "# Karpathy nanogpt -- n_embed_his == n_embed * num_head\n",
    "# he \"divides up n_embed\"\n",
    "# here we \"have multiple n_embeds\"\n",
    "#\n",
    "# > assert config.n_embd % config.n_head == 0\n",
    "# in other words\n",
    "# Karpathy nanogpt -- C_his == C * nH\n",
    "\n",
    "# Karpathy nanogpt -- k, q, v can all be computed with one giant matrix mutliply\n",
    "# TODO: try one giant matrix multiply\n",
    "\n",
    "\n",
    "# these are basically C x C matrix multiplies, given head_size * nH = C\n",
    "# C is \"n_embed\"\n",
    "\n",
    "key = nn.Linear(  C, head_size * nH, bias=False) # (C * nH, 16)\n",
    "query = nn.Linear(C, head_size * nH, bias=False) # (C * nH, 16)\n",
    "value = nn.Linear(C, head_size * nH, bias=False) # (C * nH, 16)\n",
    "\n",
    "# Now I want H different k's.\n",
    "# Goal:                                   (B, T, nH * 16)\n",
    "k = key(x)   # (B, T, C) * (C, nH * 16) = (B, T, nH * 16)\n",
    "q = query(x) # (B, T, C) * (C, nH * 16) = (B, T, nH * 16)\n",
    "\n",
    "# okay we've computed these nH matricies, but they're concatted in a row\n",
    "# Slice them up\n",
    "\n",
    "# Transformation:\n",
    "# (B, T, nH * 16) -- original\n",
    "# (B, T, nH, 16)  -- 1. split\n",
    "# (B, nH, T, 16)  -- 2. swap dimensions\n",
    "k = k.view(B, T, nH, head_size).permute((0, 2, 1, 3))  # .transpose(1, 2)\n",
    "\n",
    "# Karpathy nanogpt:\n",
    "# k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "# k = k.view(B, T, self.n_head, head_size).transpose(1, 2) # (B, nh, T, hs)\n",
    "# k = k.view(B, T, nH, head_size).transpose(1, 2) # (B, nh, T, hs)\n",
    "# Bingo\n",
    "\n",
    "q = q.view(B, T, nH, head_size).permute((0, 2, 1, 3))  # .transpose(1, 2)\n",
    "\n",
    "# (B, nH, T, 16) @ (B, nH, 16, T) = (B, nh, T, T)\n",
    "attn = q @ k.transpose(-2, -1) * C**-0.5 \n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "attn = attn.masked_fill(tril == 0, float('-inf'))\n",
    "\n",
    "attn = F.softmax(attn, dim=-1)\n",
    "\n",
    "v = value(x) # (B, T, C) @ (C, nH * 16) = (B, T, nH * 16)\n",
    "\n",
    "# Transformation:\n",
    "# (B, T, nH * 16) -- original\n",
    "# (B, T, nH, 16)  -- 1. split\n",
    "# (B, nH, T, 16)  -- 2. swap dimensions\n",
    "v = v.view(B, T, nH, head_size).permute(0, 2, 1, 3)\n",
    "att = attn @ v # (B, nh, T, T) @ (B, nH, T, 16) = (B, nH, T, 16)\n",
    "\n",
    "\n",
    "att = att.permute((0, 2, 1, 3)).reshape(B, T, nH * head_size) # (B, T, nH * 16)\n",
    "\n",
    "\n",
    "# Then we have a linear layer\n",
    "# \"output projections\"\n",
    "W = nn.Linear(nH * head_size, C, bias=False)\n",
    "out = W(att)\n",
    "\n",
    "out.shape # (B, T, C)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/slee2/karpathy-course/7_gpt.ipynb Cell 10\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/slee2/karpathy-course/7_gpt.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m num_heads \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/slee2/karpathy-course/7_gpt.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m B, T, C \u001b[39m=\u001b[39m \u001b[39m4\u001b[39m, \u001b[39m8\u001b[39m, head_size \u001b[39m*\u001b[39m num_heads \u001b[39m# batch, time, channels, num_heads\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/slee2/karpathy-course/7_gpt.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(B, T, C) \u001b[39m# (B, T, C)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/slee2/karpathy-course/7_gpt.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m w_qkv \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLinear( C, \u001b[39m3\u001b[39m \u001b[39m*\u001b[39m C, bias\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39m# (C * nH, 16)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/slee2/karpathy-course/7_gpt.ipynb#X12sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m qkv \u001b[39m=\u001b[39m w_qkv(x)   \u001b[39m# (B, T, C) * (C, nH * 16) = (B, T, 3 * C)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "import einops\n",
    "# ok multi-head attention\n",
    "\n",
    "head_size = 16\n",
    "num_heads = 5\n",
    "B, T, C = 4, 8, head_size * num_heads # batch, time, channels, num_heads\n",
    "\n",
    "x = torch.randn(B, T, C) # (B, T, C)\n",
    "\n",
    "w_qkv = nn.Linear( C, 3 * C, bias=False) # (C * nH, 16)\n",
    "qkv = w_qkv(x)   # (B, T, C) * (C, nH * 16) = (B, T, 3 * C)\n",
    "q, k, v = tuple(einops.rearrange(qkv, \"b t (h k d) -> k b h t d\", k=3, h=num_heads))\n",
    "scaled_dot_product = torch.einsum(\"b h t d, b h i d -> b h t i\", k, k) * C**-0.5 \n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "attn = scaled_dot_product.masked_fill(tril == 0, float('-inf'))\n",
    "attn = F.softmax(attn, dim=-1)\n",
    "out = torch.einsum(\"b h t t, b h t d -> b h t d\", attn, v)\n",
    "out = einops.rearrange(out, \"b h t d -> b t (h d)\")\n",
    "out.shape\n",
    "W = nn.Linear(C, C, bias=False)\n",
    "out = W(out)\n",
    "out.shape # (B, T, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A transposition is just a swap on two tensor dimensions\n",
    "test = torch.rand((3, 4, 5))\n",
    "test.permute((1, 0, 2)).allclose(test.transpose(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.4264, 0.5736, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3151, 0.3022, 0.3827, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3007, 0.2272, 0.2467, 0.2253, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1635, 0.2048, 0.1776, 0.1616, 0.2926, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1403, 0.2272, 0.1454, 0.1244, 0.2678, 0.0949, 0.0000, 0.0000],\n",
       "        [0.1554, 0.1815, 0.1224, 0.1213, 0.1428, 0.1603, 0.1164, 0.0000],\n",
       "        [0.0952, 0.1217, 0.1130, 0.1453, 0.1137, 0.1180, 0.1467, 0.1464]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0279, grad_fn=<VarBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "attention is commnunication mechanism\n",
    "\n",
    "self-attention: attention cames from same source x\n",
    "cross-attention: attention comes from another source (i.e. some other encoder block)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0964, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0651, 0.0872, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1160, 0.0963, 0.1859, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1823, 0.1080, 0.1677, 0.1842, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1094, 0.1326, 0.1498, 0.1637, 0.2794, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1386, 0.2413, 0.1775, 0.1777, 0.3875, 0.1924, 0.0000, 0.0000],\n",
       "        [0.1967, 0.2156, 0.1709, 0.2105, 0.1955, 0.4954, 0.4261, 0.0000],\n",
       "        [0.0954, 0.1190, 0.1482, 0.2639, 0.1375, 0.3122, 0.5739, 1.0000]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-3.11.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
