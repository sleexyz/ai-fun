{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 2 # batch, time, channels\n",
    "x = torch.randn(B, T, C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x bag of words\n",
    "xbow = torch.zeros((B, T, C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t + 1] # (t, C)\n",
    "        xbow[b, t] = torch.mean(xprev, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.3596, -0.9152],\n",
       "        [ 0.6258,  0.0255],\n",
       "        [ 0.9545,  0.0643],\n",
       "        [ 0.3612,  1.1679],\n",
       "        [-1.3499, -0.5102],\n",
       "        [ 0.2360, -0.2398],\n",
       "        [-0.9211,  1.5433]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.0894, -0.4926],\n",
       "        [ 0.1490, -0.3199],\n",
       "        [ 0.3504, -0.2238],\n",
       "        [ 0.3525,  0.0545],\n",
       "        [ 0.0688, -0.0396],\n",
       "        [ 0.0927, -0.0682],\n",
       "        [-0.0341,  0.1332]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "print(tril)\n",
    "attn = torch.zeros((T, T))\n",
    "attn = attn.masked_fill(tril == 0, float('-inf'))\n",
    "print(attn)\n",
    "attn = F.softmax(attn, dim=1)\n",
    "print(attn)\n",
    "xbow3 = attn @ x\n",
    "\n",
    "\n",
    "\n",
    "xbow3.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "# data dependent context\n",
    "# query and key vector\n",
    "# query: \"what am i looking for\"?\n",
    "# key: \"what do I contain\"\n",
    "# dot product between key and query\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 32 # batch, time, channels\n",
    "\n",
    "# in channel-space\n",
    "x = torch.randn(B, T, C) # (B, T, C)\n",
    "\n",
    "head_size = 16\n",
    "\n",
    "key = nn.Linear(C, head_size, bias=False)   # (C, 16)\n",
    "query = nn.Linear(C, head_size, bias=False) # (C, 16)\n",
    "value = nn.Linear(C, head_size, bias=False) # (C, 16)\n",
    "\n",
    "# we shrink to key space (features weighting importance in)\n",
    "# question: for transformers, why is one key and one query? Isn't it basically symmetric?\n",
    "k = key(x)   # (B, T, C) @ (C, 16) = (B, T, 16)\n",
    "q = query(x) # (B, T, C) @ (C, 16) = (B, T, 16)\n",
    "\n",
    "# Attention matrix\n",
    "# TxT\n",
    "attn = q @ k.transpose(-2, -1) * C**-0.5 # (B, T, 16) @ (B, 16, T)  =  (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "# wei = torch.zeros((T, T))\n",
    "\n",
    "# remove this block to make it a \"encoder block\"\n",
    "# right now it's a decoder block\n",
    "attn = attn.masked_fill(tril == 0, float('-inf'))\n",
    "\n",
    "# Softmax attention weights\n",
    "attn = F.softmax(attn, dim=-1) \n",
    "\n",
    "v = value(x)\n",
    "\n",
    "out = attn @ v # (B, T, T) @ (B, T, 16) = (B, T, 16)\n",
    "\n",
    "out.shape\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets try with einsum\n",
    "B, T, C = 4, 8, 32 # batch, time, channels\n",
    "\n",
    "x = torch.randn(B, T, C) # (B, T, C)\n",
    "head_size = 16\n",
    "\n",
    "key = nn.Linear(C, head_size, bias=False)   # (C, 16)\n",
    "query = nn.Linear(C, head_size, bias=False) # (C, 16)\n",
    "value = nn.Linear(C, head_size, bias=False) # (C, 16)\n",
    "\n",
    "k = key(x)   # (B, T, C) @ (C, 16) = (B, T, 16)\n",
    "q = query(x) # (B, T, C) @ (C, 16) = (B, T, 16)\n",
    "attn = torch.einsum(\"b i h , b j h -> b i j\", q, k) * C ** -0.5\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "attn = attn.masked_fill(tril == 0, float('-inf'))\n",
    "\n",
    "attn = F.softmax(attn, dim=-1) \n",
    "\n",
    "v = value(x)\n",
    "out = torch.einsum(\"b t t, b t h -> b t h\", attn, v)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 32])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ok multi-head attention\n",
    "B, T, C, nH = 4, 8, 32, 2 # batch, time, channels, num_heads\n",
    "\n",
    "x = torch.randn(B, T, C) # (B, T, C)\n",
    "\n",
    "head_size = 16\n",
    "\n",
    "\n",
    "# okay that's annoying. head_size * num_heads = C\n",
    "\n",
    "# Karpathy nanogpt -- n_embed_his == n_embed * num_head\n",
    "# he \"divides up n_embed\"\n",
    "# here we \"have multiple n_embeds\"\n",
    "#\n",
    "# > assert config.n_embd % config.n_head == 0\n",
    "# in other words\n",
    "# Karpathy nanogpt -- C_his == C * nH\n",
    "\n",
    "# Karpathy nanogpt -- k, q, v can all be computed with one giant matrix mutliply\n",
    "# TODO: try one giant matrix multiply\n",
    "\n",
    "\n",
    "# these are basically C x C matrix multiplies, given head_size * nH = C\n",
    "# C is \"n_embed\"\n",
    "\n",
    "key = nn.Linear(  C, head_size * nH, bias=False) # (C * nH, 16)\n",
    "query = nn.Linear(C, head_size * nH, bias=False) # (C * nH, 16)\n",
    "value = nn.Linear(C, head_size * nH, bias=False) # (C * nH, 16)\n",
    "\n",
    "# Now I want H different k's.\n",
    "# Goal:                                   (B, T, nH * 16)\n",
    "k = key(x)   # (B, T, C) * (C, nH * 16) = (B, T, nH * 16)\n",
    "q = query(x) # (B, T, C) * (C, nH * 16) = (B, T, nH * 16)\n",
    "\n",
    "# okay we've computed these nH matricies, but they're concatted in a row\n",
    "# Slice them up\n",
    "\n",
    "# Transformation:\n",
    "# (B, T, nH * 16) -- original\n",
    "# (B, T, nH, 16)  -- 1. split\n",
    "# (B, nH, T, 16)  -- 2. swap dimensions\n",
    "k = k.view(B, T, nH, head_size).permute((0, 2, 1, 3))  # .transpose(1, 2)\n",
    "\n",
    "# Karpathy nanogpt:\n",
    "# k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "# k = k.view(B, T, self.n_head, head_size).transpose(1, 2) # (B, nh, T, hs)\n",
    "# k = k.view(B, T, nH, head_size).transpose(1, 2) # (B, nh, T, hs)\n",
    "# Bingo\n",
    "\n",
    "q = q.view(B, T, nH, head_size).permute((0, 2, 1, 3))  # .transpose(1, 2)\n",
    "\n",
    "# (B, nH, T, 16) @ (B, nH, 16, T) = (B, nh, T, T)\n",
    "attn = q @ k.transpose(-2, -1) * C**-0.5 \n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "attn = attn.masked_fill(tril == 0, float('-inf'))\n",
    "\n",
    "attn = F.softmax(attn, dim=-1)\n",
    "\n",
    "v = value(x) # (B, T, C) @ (C, nH * 16) = (B, T, nH * 16)\n",
    "\n",
    "# Transformation:\n",
    "# (B, T, nH * 16) -- original\n",
    "# (B, T, nH, 16)  -- 1. split\n",
    "# (B, nH, T, 16)  -- 2. swap dimensions\n",
    "v = v.view(B, T, nH, head_size).permute(0, 2, 1, 3)\n",
    "att = attn @ v # (B, nh, T, T) @ (B, nH, T, 16) = (B, nH, T, 16)\n",
    "\n",
    "\n",
    "att = att.permute((0, 2, 1, 3)).reshape(B, T, nH * head_size) # (B, T, nH * 16)\n",
    "\n",
    "\n",
    "# Then we have a linear layer\n",
    "# \"output projections\"\n",
    "W = nn.Linear(nH * head_size, C, bias=False)\n",
    "out = W(att)\n",
    "\n",
    "out.shape # (B, T, C)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.cache/pypoetry/virtualenvs/karpathy-course-tGs3aM5M-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 80])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import einops\n",
    "# ok multi-head attention\n",
    "\n",
    "head_size = 16\n",
    "num_heads = 5\n",
    "B, T, C = 4, 8, head_size * num_heads # batch, time, channels, num_heads\n",
    "\n",
    "x = torch.randn(B, T, C) # (B, T, C)\n",
    "\n",
    "w_qkv = nn.Linear( C, 3 * C, bias=False) # (C * nH, 16)\n",
    "qkv = w_qkv(x)   # (B, T, C) * (C, nH * 16) = (B, T, 3 * C)\n",
    "q, k, v = tuple(einops.rearrange(qkv, \"b t (h k d) -> k b h t d\", k=3, h=num_heads))\n",
    "scaled_dot_product = torch.einsum(\"b h t d, b h i d -> b h t i\", k, k) * C**-0.5 \n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "attn = scaled_dot_product.masked_fill(tril == 0, float('-inf'))\n",
    "attn = F.softmax(attn, dim=-1)\n",
    "out = torch.einsum(\"b h t t, b h t d -> b h t d\", attn, v)\n",
    "out = einops.rearrange(out, \"b h t d -> b t (h d)\")\n",
    "out.shape\n",
    "W = nn.Linear(C, C, bias=False)\n",
    "out = W(out)\n",
    "out.shape # (B, T, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A transposition is just a swap on two tensor dimensions\n",
    "test = torch.rand((3, 4, 5))\n",
    "test.permute((1, 0, 2)).allclose(test.transpose(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3931, 0.6069, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2659, 0.2806, 0.4535, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1548, 0.2210, 0.1878, 0.4364, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1360, 0.1671, 0.1710, 0.1676, 0.3582, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1410, 0.1479, 0.1275, 0.1246, 0.1890, 0.2700, 0.0000, 0.0000],\n",
       "         [0.1356, 0.1034, 0.1252, 0.1046, 0.1179, 0.1567, 0.2566, 0.0000],\n",
       "         [0.1141, 0.1091, 0.1027, 0.0928, 0.1409, 0.1321, 0.1114, 0.1969]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3565, 0.6435, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2753, 0.2569, 0.4677, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2275, 0.1514, 0.2195, 0.4016, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1881, 0.1269, 0.1539, 0.1503, 0.3807, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1220, 0.1358, 0.1418, 0.1561, 0.1044, 0.3398, 0.0000, 0.0000],\n",
       "         [0.1057, 0.1668, 0.1201, 0.1182, 0.1143, 0.1216, 0.2534, 0.0000],\n",
       "         [0.1161, 0.1106, 0.1413, 0.1274, 0.1153, 0.1200, 0.1044, 0.1647]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4358, 0.5642, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2701, 0.2493, 0.4807, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1710, 0.2348, 0.2336, 0.3606, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1603, 0.2067, 0.1630, 0.1647, 0.3055, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1723, 0.1333, 0.1574, 0.1512, 0.1391, 0.2468, 0.0000, 0.0000],\n",
       "         [0.1649, 0.1200, 0.1163, 0.1138, 0.1199, 0.1167, 0.2485, 0.0000],\n",
       "         [0.1281, 0.1186, 0.0882, 0.0928, 0.1198, 0.1199, 0.1353, 0.1972]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3160, 0.6840, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2078, 0.2347, 0.5575, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1928, 0.2353, 0.2100, 0.3618, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2031, 0.1911, 0.1742, 0.1552, 0.2763, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1288, 0.1157, 0.1824, 0.1421, 0.1308, 0.3001, 0.0000, 0.0000],\n",
       "         [0.1233, 0.1275, 0.0980, 0.1135, 0.1271, 0.1518, 0.2588, 0.0000],\n",
       "         [0.1331, 0.0995, 0.0699, 0.1048, 0.1139, 0.1089, 0.1489, 0.2210]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4205, 0.5795, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3627, 0.2162, 0.4211, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1896, 0.1697, 0.2274, 0.4133, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1724, 0.1331, 0.1740, 0.2258, 0.2948, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1654, 0.1655, 0.1574, 0.1579, 0.1520, 0.2017, 0.0000, 0.0000],\n",
       "         [0.1122, 0.1543, 0.1204, 0.1414, 0.1214, 0.1444, 0.2058, 0.0000],\n",
       "         [0.1153, 0.1112, 0.1148, 0.1387, 0.1301, 0.1179, 0.1137, 0.1584]]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0295, grad_fn=<VarBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "attention is commnunication mechanism\n",
    "\n",
    "self-attention: attention cames from same source x\n",
    "cross-attention: attention comes from another source (i.e. some other encoder block)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3931, 0.6069, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2659, 0.2806, 0.4535, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1548, 0.2210, 0.1878, 0.4364, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1360, 0.1671, 0.1710, 0.1676, 0.3582, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1410, 0.1479, 0.1275, 0.1246, 0.1890, 0.2700, 0.0000, 0.0000],\n",
       "         [0.1356, 0.1034, 0.1252, 0.1046, 0.1179, 0.1567, 0.2566, 0.0000],\n",
       "         [0.1141, 0.1091, 0.1027, 0.0928, 0.1409, 0.1321, 0.1114, 0.1969]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3565, 0.6435, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2753, 0.2569, 0.4677, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2275, 0.1514, 0.2195, 0.4016, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1881, 0.1269, 0.1539, 0.1503, 0.3807, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1220, 0.1358, 0.1418, 0.1561, 0.1044, 0.3398, 0.0000, 0.0000],\n",
       "         [0.1057, 0.1668, 0.1201, 0.1182, 0.1143, 0.1216, 0.2534, 0.0000],\n",
       "         [0.1161, 0.1106, 0.1413, 0.1274, 0.1153, 0.1200, 0.1044, 0.1647]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4358, 0.5642, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2701, 0.2493, 0.4807, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1710, 0.2348, 0.2336, 0.3606, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1603, 0.2067, 0.1630, 0.1647, 0.3055, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1723, 0.1333, 0.1574, 0.1512, 0.1391, 0.2468, 0.0000, 0.0000],\n",
       "         [0.1649, 0.1200, 0.1163, 0.1138, 0.1199, 0.1167, 0.2485, 0.0000],\n",
       "         [0.1281, 0.1186, 0.0882, 0.0928, 0.1198, 0.1199, 0.1353, 0.1972]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3160, 0.6840, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2078, 0.2347, 0.5575, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1928, 0.2353, 0.2100, 0.3618, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2031, 0.1911, 0.1742, 0.1552, 0.2763, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1288, 0.1157, 0.1824, 0.1421, 0.1308, 0.3001, 0.0000, 0.0000],\n",
       "         [0.1233, 0.1275, 0.0980, 0.1135, 0.1271, 0.1518, 0.2588, 0.0000],\n",
       "         [0.1331, 0.0995, 0.0699, 0.1048, 0.1139, 0.1089, 0.1489, 0.2210]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4205, 0.5795, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3627, 0.2162, 0.4211, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1896, 0.1697, 0.2274, 0.4133, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1724, 0.1331, 0.1740, 0.2258, 0.2948, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1654, 0.1655, 0.1574, 0.1579, 0.1520, 0.2017, 0.0000, 0.0000],\n",
       "         [0.1122, 0.1543, 0.1204, 0.1414, 0.1214, 0.1444, 0.2058, 0.0000],\n",
       "         [0.1153, 0.1112, 0.1148, 0.1387, 0.1301, 0.1179, 0.1137, 0.1584]]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-3.11.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
